1. Контекст и тема лекции

· Это лекция курса CS50 по основам ИИ.
· Тема сегодняшнего занятия: анализ данных.
· Ключевой фокус: обучение без учителя (Unsupervised Learning).

2. Обучение без учителя (Unsupervised Learning)

· Отличие от обучения с учителем: в данных нет меток (labels) и нет конкретного значения, которое нужно предсказать.
· Цель: найти скрытые закономерности и структуры в неразмеченных данных.

3. Кластеризация (Clustering)

· Задача: разбить множество объектов на группы (кластеры) на основе их схожести.
· Алгоритм K-средних (K-means):
  · Нужно заранее выбрать число K (количество кластеров).
  · Алгоритм начинается со случайного размещения центров кластеров (центроидов).
  · Шаг 1: Каждая точка данных приписывается к ближайшему центроиду.
  · Шаг 2: Центроиды перемещаются в центр (среднее арифметическое) точек своего кластера.
  · Шаги 1 и 2 повторяются итеративно, пока центроиды не перестанут меняться (достигнута конвергенция).
· Ограничения K-means:
  · Результат зависит от случайного начального выбора центроидов.
  · Плохо работает с кластерами сложной формы (например, кольцо), так как ищет "круглые" скопления вокруг центра.
· Альтернатива: DBSCAN (плотностной алгоритм):
  · Основывается на плотности точек.
  · Выделяет ядровые точки (core points) — точки, вокруг которых в заданном радиусе находится минимум соседей.
  · Кластером считается связная область из ядровых точек и их соседей.
  · Точки, не попавшие ни в один кластер, считаются выбросами (outliers) или шумом.

4. Снижение размерности (Dimensionality Reduction)

· Проблема: Высокая размерность данных (много признаков) усложняет анализ и замедляет вычисления.
· Цель: Сжать данные из многих измерений (например, 10D) в меньшее количество (например, 2D), сохранив максимум полезной информации (дисперсии).
· Принцип: Проецирование точек на линию (или плоскость), которая сохраняет наибольший разброс (вариативность) данных (идея метода главных компонент, PCA).

5. Анализ ассоциативных правил (Association Rule Learning)

· Область применения: Анализ потребительской корзины (market basket analysis).
· Цель: Найти закономерности типа «если купили товар А, то, вероятно, купят и товар Б».
· Основные понятия:
  · Поддержка (Support): доля транзакций, содержащих данный набор товаров (насколько часто встречается).
  · Достоверность (Confidence): вероятность того, что при покупке набора А будет куплен товар Б (насколько правило верно).
· Алгоритм Apriori:
  · Эффективно ищет часто встречающиеся наборы товаров.
  · Принцип: если набор товаров редкий (низкая поддержка), то все более крупные наборы, включающие его, тоже будут редкими, и их можно не проверять.

6. Рекомендательные системы (Recommender Systems)

· Контентная фильтрация (Content-based Filtering):
  · Рекомендуются объекты, похожие на те, что нравились пользователю раньше.
  · Сравнение происходит по признакам (жанр, актеры, ключевые слова).
  · Для работы с текстом используется TF-IDF (частота термина и обратная частота документа), чтобы оценить важность слов в описании.
  · Для категорий (например, жанр) применяется one-hot encoding (превращение категории в набор бинарных признаков).
· Коллаборативная фильтрация (Collaborative Filtering):
  · Рекомендуется то, что понравилось другим похожим пользователям («людям с вашими вкусами понравилось также и это»).
  · Ищутся пользователи, максимально похожие на вас по истории предпочтений.

7. Дополнительно

· Аномалии (Outliers): точки данных, которые сильно отличаются от основной массы. Их поиск (детекция аномалий) важен для выявления мошенничества или нештатного поведения.
· A/B тестирование: используется для сравнения двух алгоритмов (например, рекомендательных систем) на разных группах пользователей, чтобы выбрать лучший.

1. Общие принципы работы ИИ

· Итеративность: Многие алгоритмы ИИ (включая K-means) работают по принципу «начни с плохого результата и постепенно улучшай его шаг за шагом». Это общая философия, похожая на настройку весов в нейросетях.
· Конвергенция (Сходимость): Важное понятие, означающее, что алгоритм дошел до точки, где дальнейшие итерации перестают что-либо менять. Это сигнал к остановке.

2. Глубокие нюансы алгоритмов

· K-means и форма данных: Алгоритм K-средних не просто группирует точки, он неявно предполагает, что кластеры имеют сферическую форму (похожи на круг/шар). Если данные имеют сложную форму (например, полумесяц или кольцо), K-means, скорее всего, разделит их неправильно.
· Проклятие размерности (Curse of Dimensionality): Чем больше у данных измерений (признаков), тем сложнее искать кластеры. Данные становятся «разреженными» (разбросанными), и расстояния между точками перестают быть показательными.
· DBSCAN vs K-means: DBSCAN хорош тем, что ему не нужно заранее указывать количество кластеров, и он умеет находить кластеры произвольной формы, а также автоматически отсеивать шум (аномалии).

3. Детали предобработки данных (Очень важно!)

· Проблема нумерации категорий: Нельзя просто присвоить числа категориям (например, «боевик = 1, комедия = 2»), потому что алгоритм решит, что комедия (2) ближе к боевику (1), чем фантастика (6), что может быть неправдой. Это создает ложную упорядоченность.
· One-hot encoding: Правильный способ кодирования категорий — создание отдельного бинарного столбца (0 или 1) для каждой категории. Это позволяет корректно обрабатывать фильмы, принадлежащие сразу к нескольким жанрам.

4. Работа с текстом

· TF-IDF (Term Frequency — Inverse Document Frequency): Это стандартный метод оценки важности слова в документе. Он учитывает не только частоту слова в текущем тексте (если слово "магический" встречается 3 раза), но и то, насколько это слово редко встречается в других документах (чтобы отсеять слова вроде "и", "в", "этот").

5. Коллаборативная фильтрация

· Ключевая идея: Вы ищете не похожие фильмы, а похожих людей. Анализируя историю соседей (пользователей со схожими вкусами), можно предсказать вашу реакцию на новый контент.

6. Этический и практический аспекты

· Сбор данных: Компаниям выгодно собирать как можно больше данных о вас (что вы смотрите, сколько времени, на что кликаете), так как это повышает точность их моделей, особенно для коллаборативной фильтрации.
· Тестирование моделей (A/B тестирование): Чтобы узнать, какой алгоритм лучше, компании делят пользователей на группы и показывают рекомендации от разных моделей, а затем смотрят, в какой группе метрики (клики, просмотры) оказались выше.
