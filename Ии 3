Основные метки из лекции CS50 по искусственному интеллекту (тезисно, кратко, без ссылок):

1. Тема лекции: Восприятие мира ИИ

· ИИ учится воспринимать мир через сенсорные данные (зрение, слух), подобно человеку.
· Задача: научить компьютер анализировать визуальную и звуковую информацию, чтобы делать выводы и прогнозы.

2. Как компьютер видит изображения

· Изображение для компьютера — это сетка пикселей.
· Каждый пиксель в градациях серого представляется числом (0 — черный, 1 — белый).
· Задача классификации: отнести изображение (например, рукописной цифры) к одной из категорий (0-9).

3. От нейросетей к глубокому обучению

· Простая нейросеть: входной слой (пиксели), выходной слой (категории), веса связей между ними.
· Проблема: изображения содержат огромное количество данных (например, 28x28 пикселей — это почти 800 входов).
· Решение — глубокое обучение (Deep Learning): многослойные нейросети, где каждый слой выполняет свою часть обработки.

4. Сверточные нейросети (CNN) для анализа изображений

· Идея: анализировать изображение не целиком, а небольшими участками (окнами), перемещаясь по нему.
· Свертка (Convolution): применение фильтра (ядра) — маленькой матрицы — к участку изображения для выявления признаков (например, границ, линий, углов).
· Результат свертки — карта признаков (feature map).
· Веса фильтра не задаются программистом, а обучаются нейросетью самостоятельно на основе данных.
· Преимущество сверточного слоя перед полносвязным: гораздо меньше параметров для обучения (веса одного фильтра используются для всего изображения).

5. Пулинг (Pooling) — уменьшение размерности

· Задача: уменьшить объем данных, сохранив ключевую информацию.
· Макс-пулинг (Max-Pooling): из группы пикселей (например, 2x2) выбирается один с максимальным значением.
· Это позволяет сделать модель устойчивой к небольшим смещениям объекта на картинке.

6. Архитектура сверточной нейросети

· Типичная структура:
  1. Входное изображение.
  2. Сверточный слой (Convolution) → получение карт признаков.
  3. Слой пулинга (Pooling) → сжатие данных.
  4. Повторение шагов 2 и 3 для выявления все более сложных признаков.
  5. "Выпрямление" (Flatten) данных в обычный слой нейронов.
  6. Полносвязный слой для финальной классификации.

7. Обработка цвета и видео

· Цветное изображение обрабатывается как три отдельных канала (Red, Green, Blue) со своими фильтрами.
· Видео добавляет временное измерение. Используются 3D-свертки, анализирующие изменения не только в пространстве (x, y), но и во времени (кадры).

8. Обучение и его подводные камни

· Данные делятся на тренировочный набор (для обучения) и тестовый набор (для проверки).
· Переобучение (Overfitting): модель слишком точно запоминает тренировочные данные, вместо того чтобы выявлять общие закономерности, и плохо работает с новыми примерами.
· Предвзятость (Bias): если данные необъективны (не отражают все разнообразие реальности), ИИ воспроизведет эту необъективность.

9. Эффективность и Transfer Learning

· Для обучения нейросетей эффективнее использовать GPU (видеокарты), так как они лучше справляются с параллельными вычислениями.
· Трансферное обучение (Transfer Learning): использование уже обученной модели для новой, похожей задачи. Например, дообучить сеть, распознающую собак, для распознавания кошек. Это быстрее, чем обучение с нуля. Процесс тонкой подстройки называется fine-tuning.

10. Обработка звука

· Звук — это волна. Компьютер представляет ее как набор значений в дискретные моменты времени.
· С помощью быстрого преобразования Фурье звук раскладывается на частоты.
· Результат визуализируется в виде спектрограммы — изображения, где по одной оси время, по другой — частота, а цветом показана интенсивность.
· Полученную спектрограмму можно анализировать с помощью тех же сверточных нейросетей, что и обычные картинки.
