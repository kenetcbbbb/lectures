На основе предоставленной стенограммы лекции CS50 «Основы искусственного интеллекта: Генеративный ИИ», вот основные тезисы:

1. Основной принцип генерации текста (авторегрессия)

· Языковые модели генерируют текст, предсказывая следующий токен (слово или часть слова) в последовательности.
· Процесс итеративный: сгенерированный токен добавляется к исходному запросу (промпту) и снова подается на вход модели для предсказания следующего слова.
· Обучение происходит на больших текстовых корпусах: модель учится предсказывать следующее слово на основе предыдущих (например, "Алиса" -> "была").

2. Техники улучшения ответов (Промпт-инжиниринг)

· Конкретика: Добавление деталей в запрос (например, "в июне", "люблю музеи") дает модели больше контекста для релевантного ответа.
· Детальные инструкции: Четкое описание шагов, которые модель должна выполнить для решения задачи.
· Предоставление примера (Few-shot): Включение в запрос примера того, как должен выглядеть желаемый результат.

3. Обучение с подкреплением на основе обратной связи от человека (RLHF)

· Цель: сделать ответы модели более соответствующими предпочтениям людей.
· Процесс:
  1. Люди оценивают ответы ИИ, выбирая лучшие.
  2. На этих оценках обучается отдельная модель вознаграждения, которая может предсказывать, насколько хорош ответ.
  3. Языковая модель учится получать более высокие оценки от модели вознаграждения (как в игре), корректируя свое поведение.

4. Генерация с дополненной выборкой (RAG — Retrieval-Augmented Generation)

· Решает проблему доступа к новым или личным данным (почта, документы).
· Механизм:
  1. Пользовательский запрос и все документы преобразуются в векторные представления (эмбеддинги) — числа, кодирующие смысл.
  2. Смысл запроса сравнивается со смыслом документов (поиск ближайших соседей в векторной базе данных).
  3. Наиболее релевантный документ добавляется в промпт к исходному вопросу.
  4. Обогащенный промпт передается языковой модели для генерации ответа с опорой на этот документ.

5. Генерация изображений: Генеративно-состязательная сеть (GAN)

· Архитектура из двух конкурирующих сетей:
  · Генератор: создает изображения (начинает с шума).
  · Дискриминатор: оценивает, является ли изображение реальным (из обучающей выборки) или сгенерированным.
· Процесс: Генератор учится обманывать Дискриминатор, а Дискриминатор учится лучше отличать подделку. В результате соревнования Генератор начинает создавать реалистичные изображения.

6. Генерация изображений: Вариационный автокодировщик (VAE)

· Состоит из двух частей:
  · Кодировщик: сжимает входное изображение в "код" (латентное пространство) — уменьшенное представление ключевых характеристик.
  · Декодер: восстанавливает изображение из этого кода.
· Для генерации нового изображения нужно взять случайную точку из изученного латентного пространства и пропустить её через Декодер.

7. Генерация изображений: Диффузионные модели

· Процесс обучения: берется реальное изображение и постепенно, шаг за шагом, в него добавляется шум, пока оно не превратится в чистый "шум" (статику).
· Модель учится делать обратный процесс: брать зашумленное изображение и постепенно восстанавливать (удалять шум), возвращаясь к чистому виду.
· Генерация: на вход подается случайный шум, который модель шаг за шагом "очищает", превращая в новое изображение.

8. Генерация речи (Синтез речи)

· Двухэтапный процесс:
  1. Лингвистический анализ: Текст анализируется для определения произношения, ударений и интонации (решение неоднозначностей, например, "bow").
  2. Генерация волны: Создание звуковой волны на основе анализа. Подходы:
     · Конкатенативный: Склейка заранее записанных фрагментов звуков.
     · Нейросетевой: Модель предсказывает следующее числовое значение звуковой волны на основе предыдущих (аналогично генерации текста).
