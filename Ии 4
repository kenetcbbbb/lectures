Вот основные тезисы из видео про основы ИИ для обработки естественного языка (на русском):

1. Тема лекции: Использование ИИ для понимания и обработки естественного языка (Natural Language Processing).
2. Тест Тьюринга: Классический тест для определения интеллекта машины: может ли компьютер вести диалог так, чтобы человек не отличил его от собеседника.
3. Проблема неоднозначности: Язык сложен для машин из-за неоднозначности (омонимы: "кран", различия в синтаксисе: "Он увидел её в горах с телескопом").
4. Токенизация: Первый шаг — разбиение текста на мелкие единицы (токены):
   · По словам.
   · По символам.
   · По подсловам (субвордам) — популярный метод, где " longest" может делиться на "long" + "est".
5. Анализ n-грамм: Поиск частотности последовательностей слов (биграммы: "of the", "in the"), чтобы понять контекст и предсказывать следующие слова.
6. Сентимент-анализ (Анализ тональности): Определение тона текста (позитивный/негативный) на основе встречающихся слов. Метод называется "наивный Байес".
7. Векторизация слов (Word Embeddings): Чтобы нейросеть могла работать со словами, их нужно превратить в числа (векторы). Слова со схожим значением (breakfast/lunch) получают схожие векторы и находятся близко в многомерном пространстве.
8. Рекуррентные нейросети (RNN): Архитектура для обработки последовательностей. Сеть запоминает скрытое состояние (hidden state) от предыдущих слов и использует его для анализа следующих, чтобы учитывать контекст.
9. Механизм внимания (Attention): Позволяет модели определять, на какие слова в предложении важно смотреть при анализе текущего слова (например, для понимания, что "it" относится к "Alice").
10. Трансформеры (Transformers): Современная архитектура, обрабатывающая все слова одновременно, а не по очереди.
    · Использует позиционные кодировки (positional encoding), чтобы понимать порядок слов.
    · Работает с понятиями запрос (query), ключ (key) и значение (value), чтобы перевзвешивать значимость слов и уточнять их смысл в контексте.
